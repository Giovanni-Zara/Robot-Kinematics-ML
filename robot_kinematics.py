# -*- coding: utf-8 -*-
"""Robot_Kinematics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/135YnaIta7dUSLPvoHmW7UTMfhdzYxGd9
"""

from google.colab import drive
drive.mount('/content/drive',force_remount = True)
#DECIDERE SE MOUNTARE DRIVE O METTEERE I LOGFILE MANUALMENTE

"""#2 joints robot (r2)

##Explorative data analisys

### r2 dataset
"""

import pandas as pd

# Load the CSV file with the correct delimiter
file_path = '/content/drive/MyDrive/homework ML/ML/MLHW1_robot_kinematics/logfile_r2.csv'  # path to logfile r2-> that's the dataset generated for the 2D 2 joint robot
data_r2 = pd.read_csv(file_path, delimiter=';')

# Separate features and labels
features_r2 = data_r2[['j0', 'j1']]
labels_r2 = data_r2[['ft_x', 'ft_y', 'ft_qw', 'ft_qz']]

"""###r2 with 1492 seed dataset"""

import pandas as pd

# Load the CSV file with the correct delimiter
file_path = '/content/drive/MyDrive/homework ML/ML/MLHW1_robot_kinematics/logfile_seed1492_r2.csv'
data_r2_1492 = pd.read_csv(file_path, delimiter=';')

# Separate features and labels
features_r2_1492 = data_r2_1492[['j0', 'j1']]
labels_r2_1492 = data_r2_1492[['ft_x', 'ft_y', 'ft_qw', 'ft_qz']]

features_r2

labels_r2

from tabulate import tabulate
print(tabulate(data_r2.describe(), headers='keys', tablefmt='fancy_grid'))

from tabulate import tabulate
print(tabulate(data_r2.head(20), headers='keys', tablefmt='fancy_grid'))

import matplotlib.pyplot as plt

# Assuming `df` is your pandas DataFrame
plt.figure(figsize=(8, 6))
plt.scatter(data_r2['ft_x'], data_r2['ft_y'], s=5, alpha=0.7, c='blue')  # Adjust marker size and color as needed
plt.title('Robot Workspace (2D) based on my 1000 positions')
plt.xlabel('ft_x (X-coordinate)')
plt.ylabel('ft_y (Y-coordinate)')
plt.grid(True)
plt.axis('equal')  # Ensure equal scaling for X and Y axes
plt.show()

"""###Workspace and coordinates density distibution"""

#To observe the fingertip's position distribution in 2D space
import seaborn as sns
sns.set(style="whitegrid")
sns.jointplot(x='ft_x', y='ft_y', data=labels_r2, kind='scatter', color='blue')

"""##Data splitting
For this section, I will use a different generation seed for training and testing datas to ensure the maximum generalization.
So, I'm gonna split both datasets (with two different seeds) in training and testing (80%-20%) but ignoring first dataset's test subset and second dataset's train subset.
"""

from sklearn.model_selection import train_test_split
#using features with base seed and labels with different seed
Xr2_train, Xr2_test_disposable, Yr2_train, Yr2_test_disposable = train_test_split(features_r2, labels_r2, test_size=0.2, random_state=42)
Xr2_train_disposable, Xr2_test, Yr2_train_disposable, Yr2_test = train_test_split(features_r2_1492, labels_r2_1492, test_size=0.2, random_state=42)

"""##Model
Since I am working with a 2DOF robotic arm, a feedforward neural network (NN) is a good choice.
I will try a linear simple model with no middle layer (approximating a linear regression) and then a more complete one, to denote the differences.
The goal of the model is to learn a mapping from joint angles and their trigonometric values to the fingertip position (x, y) and orientation (quaternion values).

Steps:

Input Features:j0, j1, cos(j0), cos(j1), sin(j0), and sin(j1) as inputs.

Output (Target):ft_x, ft_y, ft_qw, ft_qz (fingertip position and orientation).

Loss Function: Mean Squared Error (MSE) is appropriate for regression problems.

"""

!pip install scikeras

"""##first try

###Loss Function and Optimizer
Loss Function: Mean Squared Error (MSE) for this regression task.

Optimizer: Adam optimizer is commonly used and works well for most cases.

###Hyperparameter Search
I chose two hyperparameters to tune: lr and epochs.

I'll iterate on 2 different lr and 3 sets of epochs, for a total of 6 combinations.

I'll do a grid search and a 5-time cross validation using scikit learn function GridSearchCV, so I try all the parameters and all the possible train-validation sets.

For simplicity I'll be using scikeras, a wrapper around Keras that has an Scikit-Learn interface.
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import GridSearchCV, KFold
from sklearn.metrics import mean_squared_error
from scikeras.wrappers import KerasRegressor

def create_model(learning_rate=0.001):
    model = keras.Sequential([
        layers.InputLayer(shape=(Xr2_train.shape[1],)),
        layers.Dense(Yr2_train.shape[1], activation='linear')  # Linear output layer
    ])


    # Compile the model with Adam optimizer and MSE loss
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
                  loss='mean_squared_error')

    return model

# Wrap the model for use in GridSearchCV
def create_model_wrapper(learning_rate=0.001):
    return KerasRegressor(model=create_model, learning_rate=learning_rate, epochs=10, batch_size=32, verbose=0)

# Hyperparameters for Grid Search
param_grid = {
    'learning_rate': [0.001, 0.01, 0.1],  # Example learning rates
    'epochs': [20, 30, 50]  # Example number of epochs
}

# Cross-validation setup
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Perform grid search
grid_search_lr = GridSearchCV(estimator=create_model_wrapper(), param_grid=param_grid, cv=kf, scoring='neg_mean_squared_error', verbose = 10)

# Perform grid search to find the best hyperparameters
grid_search_lr.fit(Xr2_train, Yr2_train)

# Get best parameters and results
best_params = grid_search_lr.best_params_
print("Best Parameters from Grid Search:", best_params)

best_score = grid_search_lr.best_score_
print("Best MSE Score from Grid Search:", best_score)

"""###evalutation and metrics"""

# Create the best model with the selected hyperparameters
best_model_lr = create_model(learning_rate=best_params['learning_rate'])

# Train the model on the entire training data with the best epochs
history_lr = best_model_lr.fit(Xr2_train, Yr2_train, epochs=best_params['epochs'], batch_size=32, verbose=1, validation_split=0.2)

# Evaluate the model on the test data
test_loss_lr = best_model_lr.evaluate(Xr2_test, Yr2_test, verbose=0)
print(f"Test Loss (MSE): {test_loss_lr}")

# Predict the position and orientation
predictions_lr = best_model_lr.predict(Xr2_test)

# Calculate Mean Squared Error (MSE) on predictions
mse_lr = mean_squared_error(Yr2_test, predictions_lr)
print(f"Test MSE: {mse_lr}")

import matplotlib.pyplot as plt

# Plot training and validation loss
def plot_loss_curves(history):
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss (MSE)')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid()
    plt.show()

# Assuming you stored the training history from `fit`
plot_loss_curves(history_lr)

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D  # Import 3D plotting toolkit

# Convert to NumPy arrays
Y_true = Yr2_test.to_numpy() if not isinstance(Yr2_test, np.ndarray) else Yr2_test
Y_pred = predictions_lr if isinstance(predictions_lr, np.ndarray) else np.array(predictions_lr)

# Scatter plot function for 3D
def scatter_ground_truth_vs_predictions_3D(Y_true, Y_pred):
    fig = plt.figure(figsize=(10, 6))
    ax = fig.add_subplot(111, projection='3d')  # Create a 3D axis

    # Scatter plot for Ground Truth
    ax.scatter(Y_true[:, 0], Y_true[:, 1], Y_true[:, 2], label='Ground Truth', alpha=0.7, color='blue')

    # Scatter plot for Predictions
    ax.scatter(Y_pred[:, 0], Y_pred[:, 1], Y_pred[:, 2], label='Predictions', alpha=0.7, color='orange')

    # Labels and title
    ax.set_xlabel('X Position')
    ax.set_ylabel('Y Position')
    ax.set_zlabel('Z Position')
    ax.set_title('Ground Truth vs. Predicted Points (3D)')
    ax.legend()
    ax.grid()

    # Set axis limits with a larger scale (0.5)
    x_min = min(Y_true[:, 0].min(), Y_pred[:, 0].min()) - 0.3
    x_max = max(Y_true[:, 0].max(), Y_pred[:, 0].max()) + 0.3
    y_min = min(Y_true[:, 1].min(), Y_pred[:, 1].min()) - 0.3
    y_max = max(Y_true[:, 1].max(), Y_pred[:, 1].max()) + 0.3
    z_min = min(Y_true[:, 2].min(), Y_pred[:, 2].min()) - 0.3
    z_max = max(Y_true[:, 2].max(), Y_pred[:, 2].max()) + 0.3

    # Apply the new limits to zoom out and increase the scale
    ax.set_xlim(x_min, x_max)
    ax.set_ylim(y_min, y_max)
    ax.set_zlim(z_min, z_max)

    # Show the plot
    plt.show()

# Call the function
scatter_ground_truth_vs_predictions_3D(Y_true, Y_pred)

"""##second try to enhance performances"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import GridSearchCV, KFold
from sklearn.metrics import mean_squared_error
from scikeras.wrappers import KerasRegressor

def create_model(learning_rate=0.001):
    model = keras.Sequential([
        layers.InputLayer(shape=(Xr2_train.shape[1],)),
        layers.Dense(64, activation='relu'),
        layers.Dense(Yr2_train.shape[1], activation='linear')  # Linear output layer
    ])


    # Compile the model with Adam optimizer and MSE loss
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
                  loss='mean_squared_error')

    return model

# Wrap the model for use in GridSearchCV
def create_model_wrapper(learning_rate=0.001):
    return KerasRegressor(model=create_model, learning_rate=learning_rate, epochs=10, batch_size=32, verbose=0)

# Hyperparameters for Grid Search
param_grid = {
    'learning_rate': [0.001, 0.01, 0.1],  # Example learning rates
    'epochs': [20, 30, 50]  # Example number of epochs
}

# Cross-validation setup
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Perform grid search
grid_search = GridSearchCV(estimator=create_model_wrapper(),refit=True, param_grid=param_grid, cv=kf, scoring='neg_mean_squared_error', verbose = 10)

# Perform grid search to find the best hyperparameters
grid_search.fit(Xr2_train, Yr2_train)

# Get best parameters and results
best_params = grid_search.best_params_
print("Best Parameters from Grid Search:", best_params)

best_score = grid_search.best_score_
print("Best MSE Score from Grid Search:", best_score)

"""###evalutation and metrics"""

# Create the best model with the selected hyperparameters
best_model = create_model(learning_rate=best_params['learning_rate'])

# Train the model on the entire training data with the best epochs
history = best_model.fit(Xr2_train, Yr2_train, epochs=best_params['epochs'], batch_size=32, verbose=1, validation_split=0.2)

# Evaluate the model on the test data
test_loss = best_model.evaluate(Xr2_test, Yr2_test, verbose=0)
print(f"Test Loss (MSE): {test_loss}")

# Predict the position and orientation
predictions = best_model.predict(Xr2_test)

# Calculate Mean Squared Error (MSE) on predictions
mse = mean_squared_error(Yr2_test, predictions)
print(f"Test MSE: {mse}")

"""##plots analysis"""

import matplotlib.pyplot as plt
import pandas as pd

# Convert cv_results_ to a DataFrame for easier handling
results_df = pd.DataFrame(grid_search.cv_results_)

# Plot mean test scores (negative MSE) for each parameter combination
plt.figure(figsize=(12, 6))
for lr in results_df['param_learning_rate'].unique():
    subset = results_df[results_df['param_learning_rate'] == lr]
    plt.plot(subset['param_epochs'], -subset['mean_test_score'], label=f'LR={lr}', marker='o')

plt.title('Validation Scores Across Epochs and Learning Rates')
plt.xlabel('Epochs')
plt.ylabel('Validation MSE (lower is better)')
plt.legend()
plt.grid()
plt.show()

import matplotlib.pyplot as plt

# Plot training and validation loss
def plot_loss_curves(history):
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss (MSE)')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid()

    # Set y-axis limits with a larger scale (0.5)
    y_min = min(min(history.history['loss']), min(history.history['val_loss'])) - 0.04
    y_max = max(max(history.history['loss']), max(history.history['val_loss'])) + 0.04

    # Apply the new limits to increase the scale
    plt.ylim(y_min, y_max)

    plt.show()

# Assuming you stored the training history from `fit`
plot_loss_curves(history)

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D  # Import 3D plotting toolkit
import numpy as np  # Ensure NumPy is imported

# Convert to NumPy arrays
Y_true = Yr2_test.to_numpy() if not isinstance(Yr2_test, np.ndarray) else Yr2_test
Y_pred = predictions if isinstance(predictions, np.ndarray) else np.array(predictions)

# Plot function for all requested layouts
def plot_3D_scenarios(Y_true, Y_pred):
    fig = plt.figure(figsize=(20, 6))  # Adjusted width for three plots

    # 1. Ground Truth plot
    ax1 = fig.add_subplot(131, projection='3d')  # First subplot
    ax1.scatter(Y_true[:, 0], Y_true[:, 1], Y_true[:, 2], label='Ground Truth', alpha=0.7, color='blue')
    ax1.set_title('Ground Truth Points (3D)')
    ax1.set_xlabel('X Position')
    ax1.set_ylabel('Y Position')
    ax1.set_zlabel('Z Position')
    ax1.legend()
    ax1.grid()

    # 2. Predictions plot
    ax2 = fig.add_subplot(132, projection='3d')  # Second subplot
    ax2.scatter(Y_pred[:, 0], Y_pred[:, 1], Y_pred[:, 2], label='Predictions', alpha=0.7, color='orange')
    ax2.set_title('Predicted Points (3D)')
    ax2.set_xlabel('X Position')
    ax2.set_ylabel('Y Position')
    ax2.set_zlabel('Z Position')
    ax2.legend()
    ax2.grid()

    # 3. Combined scatter plot
    ax3 = fig.add_subplot(133, projection='3d')  # Third subplot
    ax3.scatter(Y_true[:, 0], Y_true[:, 1], Y_true[:, 2], label='Ground Truth', alpha=0.7, color='blue',s=40)
    ax3.scatter(Y_pred[:, 0], Y_pred[:, 1], Y_pred[:, 2], label='Predictions', alpha=0.7, color='orange',s=40)
    ax3.set_title('Ground Truth vs Predictions (3D)')
    ax3.set_xlabel('X Position')
    ax3.set_ylabel('Y Position')
    ax3.set_zlabel('Z Position')
    ax3.legend()
    ax3.grid()

    # Adjust spacing between subplots
    plt.tight_layout()

    # Show the plots
    plt.show()

# Call the function
plot_3D_scenarios(Y_true, Y_pred)

"""###Compute the Jacobian Matrix 𝐽
J represents the partial derivatives of each fingertip position and orientation component with respect to the joint angles.

Analytical Jacobian: This requires the robot’s forward kinematic equations, which relate joint angles to the fingertip position and orientation.
Learned Jacobian: Compute this using automatic differentiation with the trained NN model
"""

import tensorflow as tf

def FK(model,theta):
    # reshape to batch size 1
    t = tf.reshape(theta, shape=(1,2))
    out = model(t)
    # reshape to 1d vector
    out = tf.reshape(out, shape=(4,))
    return out

@tf.function
def FK_Jacobian(model,x):
  with tf.GradientTape(persistent=True) as tape:
    tape.watch(x)
    y = FK(model,x)
  return tape.jacobian(y, x)

"""###Analytical Jacobian
Calculate the analytical Jacobian using the following known FK equations:

$$
x = L_1 \cos(\theta_1) + L_2 \cos(\theta_1 + \theta_2)
$$
$$
y = L_1 \sin(\theta_1) + L_2 \sin(\theta_1 + \theta_2)
$$

To compute the jacobian I have to do partial derivatives of x and y wrt each other.

$$
\frac{\partial x}{\partial \theta_1} = -L_1 \sin(\theta_1) - L_2 \sin(\theta_1 + \theta_2)
$$

$$
\frac{\partial x}{\partial \theta_2} = -L_2 \sin(\theta_1 + \theta_2)
$$

$$
\frac{\partial y}{\partial \theta_1} = L_1 \cos(\theta_1) + L_2 \cos(\theta_1 + \theta_2)
$$

$$
\frac{\partial y}{\partial \theta_2} = L_2 \cos(\theta_1 + \theta_2)
$$

The Jacobian matrix
𝐽 is:

$$
J = \begin{bmatrix}
\frac{\partial x}{\partial \theta_1} & \frac{\partial x}{\partial \theta_2} \\
\frac{\partial y}{\partial \theta_1} & \frac{\partial y}{\partial \theta_2}
\end{bmatrix}
$$

Substituting the computed derivatives:

$$
J = \begin{bmatrix}
-L_1 \sin(\theta_1) - L_2 \sin(\theta_1 + \theta_2) & -L_2 \sin(\theta_1 + \theta_2) \\
L_1 \cos(\theta_1) + L_2 \cos(\theta_1 + \theta_2) & L_2 \cos(\theta_1 + \theta_2)
\end{bmatrix}
$$

So, final jacobian is:

$$
J = \begin{bmatrix}
-L_1 \sin(\theta_1) - L_2 \sin(\theta_1 + \theta_2) & -L_2 \sin(\theta_1 + \theta_2) \\
L_1 \cos(\theta_1) + L_2 \cos(\theta_1 + \theta_2) & L_2 \cos(\theta_1 + \theta_2)
\end{bmatrix}
$$




"""

import numpy as np
import math as m
# Example:
j1 = Xr2_train['j0'][1]
j2 = Xr2_train['j1'][1]
analytical_jacobian = np.array(
                                [[(-0.1 * m.sin(j1)) - (0.1 * m.sin(j1+j2)), -0.1 * m.sin(j1+j2)],
                                [( 0.1 * m.cos(j1)) + (0.1 * m.cos(j1+j2)),  0.1 * m.cos(j1+j2)]]
                              )

"""###Compute distances and compare the Learned Jacobians to the Analytical Jacobian

To compare:


Compare element-by-element or using a norm (e.g., Frobenius norm).
"""

differences = []
for i in Xr2_test.index:
  j1 = Xr2_test['j0'][i]
  j2 = Xr2_test['j1'][i]

  x = [j1, j2]
  t = tf.constant(x, dtype=tf.float32)
  jacobian_r2 = FK_Jacobian(best_model, t)
  analytical_jacobian_r2 = np.array(
                                  [[(-0.1 * m.sin(j1)) - (0.1 * m.sin(j1+j2)), -0.1 * m.sin(j1+j2)],
                                  [( 0.1 * m.cos(j1)) + (0.1 * m.cos(j1+j2)),  0.1 * m.cos(j1+j2)]]
                                )
  # Print the Jacobian matrix
  jacobian_r2.numpy()  # Convert TensorFlow tensor to NumPy array for readability
  jacobian_r2 = np.delete(jacobian_r2, [2,3], axis=0)    #I'm gonna remove the part of the jacobian that refers to quaternions as I want just positions
  # Assuming analytical_J and learned_J are the Jacobian matrices
  diff = np.linalg.norm(analytical_jacobian_r2 - jacobian_r2, ord='fro')
  differences.append(diff)

print(f"the difference of jacobians has been computed on {len(differences)} samples")  #number of differences calculated
mean = np.mean(differences)
print(f"The mean of all the differences is: {mean}")

"""# 3 joints robot (r3)

## Explorative data analisys

###r3 dataset
"""

import pandas as pd

# Load the CSV file with the correct delimiter
file_path = '/content/drive/MyDrive/homework ML/ML/MLHW1_robot_kinematics/logfile_r3.csv'
data_r3 = pd.read_csv(file_path, delimiter=';')

# Separate features and labels
features_r3 = data_r3[['j0', 'j1', 'j2']]
labels_r3 = data_r3[['ft_x', 'ft_y', 'ft_qw', 'ft_qz']]

"""###r3 with 1492 seed dataset"""

import pandas as pd

# Load the CSV file with the correct delimiter
file_path = '/content/drive/MyDrive/homework ML/ML/MLHW1_robot_kinematics/logfile_seed1492_r3.csv'
data_r3_1492 = pd.read_csv(file_path, delimiter=';')

# Separate features and labels
features_r3_1492 = data_r3_1492[['j0', 'j1', 'j2']]
labels_r3_1492 = data_r3_1492[['ft_x', 'ft_y', 'ft_qw', 'ft_qz']]

from tabulate import tabulate
print(tabulate(data_r3.head(20), headers='keys', tablefmt='fancy_grid'))

from tabulate import tabulate
print(tabulate(data_r3.describe(), headers='keys', tablefmt='fancy_grid'))

features_r3.head()

labels_r3.head()

"""###Workspace and coordinates density distibution"""

#To observe the fingertip's position distribution in 2D space
import seaborn as sns
sns.set(style="whitegrid")
sns.jointplot(x='ft_x', y='ft_y', data=data_r3, kind='scatter', color='blue')

"""##data splitting"""

from sklearn.model_selection import train_test_split
#using features with base seed and labels with different seed
Xr3_train, Xr3_test_disposable, Yr3_train, Yr3_test_disposable = train_test_split(features_r3, labels_r3, test_size=0.2, random_state=42)
Xr3_train_disposable, Xr3_test, Yr3_train_disposable, Yr3_test = train_test_split(features_r3_1492, labels_r3_1492, test_size=0.2, random_state=42)

"""##MODEL-adaboosting - first try
For this robot configuration I'd like to try computing the problems using adaboosting.

An AdaBoost regressor is a meta-estimator that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. As such, subsequent regressors focus more on difficult cases.

Analyzing r2 I've seen that the linear regression poorly approximates the problem, so I'd like to try how a regressions ensemble performs.
I'm gonna use support vector machines regressors (SVR) to try to catch better the non-linear features.
"""

from sklearn.ensemble import AdaBoostRegressor
from sklearn.multioutput import MultiOutputRegressor
from sklearn.svm import SVR
from sklearn.model_selection import KFold, GridSearchCV

SVR_estimator = SVR()
model =  MultiOutputRegressor(AdaBoostRegressor(estimator = SVR_estimator))

param_grid = {
    'estimator__learning_rate' : [0.1, 0.01, 0.001],
    'estimator__n_estimators' : [70, 90],
    'estimator__estimator__epsilon': [0.01, 0.1],  #It specifies the epsilon-tube within which no penalty is associated in the training loss function with points predicted within a distance epsilon from the actual value.
    'estimator__estimator__kernel': ['linear', 'rbf']
}

kf = KFold(n_splits=5, shuffle=True, random_state=42)
grid_search_r3 = GridSearchCV(
    estimator=model,
    param_grid=param_grid,
    cv=kf,
    scoring='neg_mean_squared_error',
    verbose = 10,
    )

grid_search_r3.fit(Xr3_train, Yr3_train)    ##computing grid search

# Get best parameters and results
best_params_r3 = grid_search_r3.best_params_
print("Best Parameters from Grid Search:", best_params_r3)

best_score_r3 = grid_search_r3.best_score_
print("Best MSE Score from Grid Search:", best_score_r3)

"""###metrics evaluation"""

best_score = -grid_search_r3.best_score_

best_params_r3
model =  MultiOutputRegressor(AdaBoostRegressor(estimator = SVR_estimator))

print("Best MSE Score from Grid Search:", best_score)

# Refit the best model with best parameters
best_model = grid_search_r3.best_estimator_

#PUT HERE BEST MODEL TO REFIT FOR CURVES AND GRAPHS
best_SVR_estimator = SVR(
    kernel = best_params_r3['estimator__estimator__kernel'],
    epsilon = best_params_r3['estimator__estimator__epsilon']
    )
best_model_r3 = MultiOutputRegressor(
    AdaBoostRegressor(
    estimator=best_SVR_estimator,
    learning_rate = best_params_r3['estimator__learning_rate'],
    n_estimators = best_params_r3['estimator__n_estimators']
    )
)

from sklearn.metrics import mean_squared_error
history = best_model_r3.fit(Xr3_train, Yr3_train)

predictions = best_model_r3.predict(Xr3_test)

# Calculate Mean Squared Error on the test set
test_mse = mean_squared_error(Yr3_test, predictions)
print(f"Test MSE: {test_mse}")

import numpy as np
import matplotlib.pyplot as plt

# Define subsets for incremental training
train_sizes = np.linspace(0.1, 1.0, 10)  # 10 steps from 10% to 100% of the training set

train_errors = []
test_errors = []

for train_size in train_sizes:
    # Get a subset of the training data
    subset_size = int(train_size * len(Xr3_train))
    X_train_subset = Xr3_train[:subset_size]
    Y_train_subset = Yr3_train[:subset_size]

    # Train the model on the subset
    best_model_r3.fit(X_train_subset, Y_train_subset)

    # Evaluate on the training subset
    train_predictions = best_model_r3.predict(X_train_subset)
    train_mse = mean_squared_error(Y_train_subset, train_predictions)
    train_errors.append(train_mse)

    # Evaluate on the full test set
    test_predictions = best_model_r3.predict(Xr3_test)
    test_mse = mean_squared_error(Yr3_test, test_predictions)
    test_errors.append(test_mse)

# Plot learning curves
plt.figure(figsize=(10, 6))
plt.plot(train_sizes * len(Xr3_train), train_errors, label='Training Error', marker='o')
plt.plot(train_sizes * len(Xr3_train), test_errors, label='Test Error', marker='o')
plt.title('Learning Curves')
plt.xlabel('Training Set Size')
plt.ylabel('Mean Squared Error')
plt.legend()
plt.grid()
plt.show()

from sklearn.model_selection import learning_curve
import numpy as np
import matplotlib.pyplot as plt

# Define train sizes (percentage of the training set)
train_sizes = np.linspace(0.1, 1.0, 10)  # 10 points from 10% to 100%

# Calculate learning curves
train_sizes, train_scores, validation_scores = learning_curve(
    estimator=best_model_r3,
    X=Xr3_train,
    y=Yr3_train,
    train_sizes=train_sizes,
    cv=5,  # Number of folds for cross-validation
    scoring='neg_mean_squared_error',  # Use MSE for scoring
    n_jobs=-1,
    verbose=10
)

# Convert negative MSE to positive
train_errors = -train_scores.mean(axis=1)
validation_errors = -validation_scores.mean(axis=1)

# Plot learning curves
plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_errors, label='Training Error', marker='o')
plt.plot(train_sizes, validation_errors, label='Validation Error', marker='o')
plt.title('Learning Curves')
plt.xlabel('Training Set Size')
plt.ylabel('Mean Squared Error')
plt.legend()
plt.grid()
plt.show()

"""##second try

####Enhance performance
I notice a significant difference between the best model train loss (5.116611834495398e-05) and the best model test loss (0.00259425417181913).
This discrepancy may indicate that the model overfits on the train set.
there could be different reasons, but the main one could be the little dataset dimension.
For a more complex problem, as r3, I could consider to pick dataset with more samples.

I will now retry the training and hyperparameter search with a larger dataset: 10ksamples

####larger r3 dataset
"""

import pandas as pd

# Load the CSV file with the correct delimiter
file_path = '/content/drive/MyDrive/homework ML/ML/MLHW1_robot_kinematics/dataset_r3_10ksamples_seed1000.csv'
data_r3_10k = pd.read_csv(file_path, delimiter=';')

# Separate features and labels
features_r3_10k = data_r3_10k[['j0', 'j1', 'j2']]
labels_r3_10k = data_r3_10k[['ft_x', 'ft_y', 'ft_qw', 'ft_qz']]

import pandas as pd

# Load the CSV file with the correct delimiter
file_path = '/content/drive/MyDrive/homework ML/ML/MLHW1_robot_kinematics/dataset_r3_10ksamples_seed1492.csv'
data_r3_1492_10k = pd.read_csv(file_path, delimiter=';')

# Separate features and labels
features_r3_1492_10k = data_r3_1492_10k[['j0', 'j1', 'j2']]
labels_r3_1492_10k = data_r3_1492_10k[['ft_x', 'ft_y', 'ft_qw', 'ft_qz']]

#To observe the fingertip's position distribution in 2D space
import seaborn as sns
sns.set(style="whitegrid")
sns.jointplot(x='ft_x', y='ft_y', data=data_r3_10k, kind='scatter', color='blue')

"""###data splitting"""

from sklearn.model_selection import train_test_split
#using features with base seed and labels with different seed
Xr3_10k_train, Xr3_10k_test_disposable, Yr3_10k_train, Yr3_10k_test_disposable = train_test_split(features_r3_10k, labels_r3_10k, test_size=0.2, random_state=42)
Xr3_10k_train_disposable, Xr3_10k_test, Yr3_10k_train_disposable, Yr3_10k_test = train_test_split(features_r3_1492_10k, labels_r3_1492_10k, test_size=0.2, random_state=42)

"""###same model
I just reduced some hyperparameters for computational time problems
"""

from sklearn.ensemble import AdaBoostRegressor
from sklearn.multioutput import MultiOutputRegressor
from sklearn.svm import SVR
from sklearn.model_selection import KFold, GridSearchCV

SVR_estimator = SVR()
model =  MultiOutputRegressor(AdaBoostRegressor(estimator = SVR_estimator))

param_grid = {
    'estimator__learning_rate' : [0.1, 0.01, 0.001],
    'estimator__n_estimators' : [80],
    'estimator__estimator__epsilon': [0.01, 0.1],  #It specifies the epsilon-tube within which no penalty is associated in the training loss function with points predicted within a distance epsilon from the actual value.
    'estimator__estimator__kernel': ['rbf']
}

kf = KFold(n_splits=5, shuffle=True, random_state=42)
grid_search_r3_10k = GridSearchCV(
    estimator=model,
    param_grid=param_grid,
    cv=kf,
    scoring='neg_mean_squared_error',
    verbose = 10,
    )

grid_search_r3_10k.fit(Xr3_10k_train, Yr3_10k_train)    ##computing grid search

# Get best parameters and results
best_params_r3_10k = grid_search_r3_10k.best_params_
print("Best Parameters from Grid Search:", best_params_r3_10k)

best_score_r3_10k = grid_search_r3_10k.best_score_
print("Best MSE Score from Grid Search:", best_score_r3_10k)

best_params_r3_10k = grid_search_r3_10k.best_params_
print("Best Parameters from Grid Search:", best_params_r3_10k)

best_score_r3_10k = grid_search_r3_10k.best_score_
print("Best MSE Score from Grid Search:", -best_score_r3_10k)

"""###metrics evaluation"""

SVR_estimator = SVR(epsilon=0.01, kernel='rbf')

# Initialize AdaBoostRegressor with the SVR estimator and specific parameters
ada_boost_estimator = AdaBoostRegressor(
    estimator=SVR_estimator,
    learning_rate=0.1,
    n_estimators=80
)

# Wrap AdaBoostRegressor with MultiOutputRegressor for multi-output regression
model = MultiOutputRegressor(ada_boost_estimator)

#PUT HERE BEST MODEL TO REFIT FOR CURVES AND GRAPHS

best_SVR_estimator_10k = SVR(
    kernel = best_params_r3_10k['estimator__estimator__kernel'],
    epsilon = best_params_r3_10k['estimator__estimator__epsilon']
    )
best_model_r3_10k = MultiOutputRegressor(
    AdaBoostRegressor(
    estimator=best_SVR_estimator_10k,
    learning_rate = best_params_r3_10k['estimator__learning_rate'],
    n_estimators = best_params_r3_10k['estimator__n_estimators']
    )
)

from sklearn.metrics import mean_squared_error
print('fit start')
history = model.fit(Xr3_10k_train, Yr3_10k_train)
print('fit end')  #debugging prints

print('prediction start')
predictions = model.predict(Xr3_10k_test)
print('prediction end')
# Calculate Mean Squared Error on the test set
test_mse_10k = mean_squared_error(Yr3_10k_test, predictions)
print(f"Test MSE: {test_mse_10k}")

"""I notice that the train loss is now consistent with the test loss as they have the same order of magnitude.

So the overfitting problem seems solved
"""

from sklearn.model_selection import learning_curve
import numpy as np
import matplotlib.pyplot as plt

# Define train sizes (percentage of the training set)
train_sizes = np.linspace(0.1, 1.0, 10)  # 10 points from 10% to 100%

# Calculate learning curves
train_sizes, train_scores, validation_scores = learning_curve(
    estimator=best_model_r3_10k,
    X=Xr3_10k_train,
    y=Yr3_10k_train,
    train_sizes=train_sizes,
    cv=5,  # Number of folds for cross-validation
    scoring='neg_mean_squared_error',  # Use MSE for scoring
    n_jobs=-1,
    verbose=10
)

# Convert negative MSE to positive
train_errors = -train_scores.mean(axis=1)
validation_errors = -validation_scores.mean(axis=1)

# Plot learning curves
plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_errors, label='Training Error', marker='o')
plt.plot(train_sizes, validation_errors, label='Validation Error', marker='o')
plt.title('Learning Curves')
plt.xlabel('Training Set Size')
plt.ylabel('Mean Squared Error')
plt.legend()
plt.grid()
plt.show()

"""##Compute the Jacobian Matrix 𝐽"""

import random
import numpy as np
import warnings

def model_forward_3to4(model, params):
    # Temporarily suppress warnings inside this function
    with warnings.catch_warnings():     #using this to avoid to print all warnings. For readability
        warnings.filterwarnings("ignore", category=UserWarning)
        predictions = model.predict([params])  # Ensure params is passed as a list
    outputs = predictions.flatten()  # Flatten to ensure it's a 1D array
    return outputs[:2]  # Return only the position values

def compute_jacobian_numerically(model, input_values, delta):
    jacobian_matrix = np.zeros((2, 3))

    for idx in range(3):  # Iterate over the three input parameters
        perturbed_forward = input_values.copy()
        perturbed_forward[idx] += delta
        forward_result = model_forward_3to4(model, perturbed_forward)

        perturbed_backward = input_values.copy()
        perturbed_backward[idx] -= delta
        backward_result = model_forward_3to4(model, perturbed_backward)

        # Use central difference method for approximation
        diff = (forward_result - backward_result) / (2 * delta)
        jacobian_matrix[:, idx] = diff

    return jacobian_matrix

def calc_analytical_jacobian(joint_angles):
    theta1, theta2, theta3 = joint_angles
    segment_lengths = [0.1, 0.1, 0.1]

    L1, L2, L3 = segment_lengths

    partial_x_theta1 = -L1 * np.sin(theta1) - L2 * np.sin(theta1 + theta2) - L3 * np.sin(theta1 + theta2 + theta3)
    partial_x_theta2 = -L2 * np.sin(theta1 + theta2) - L3 * np.sin(theta1 + theta2 + theta3)
    partial_x_theta3 = -L3 * np.sin(theta1 + theta2 + theta3)

    partial_y_theta1 = L1 * np.cos(theta1) + L2 * np.cos(theta1 + theta2) + L3 * np.cos(theta1 + theta2 + theta3)
    partial_y_theta2 = L2 * np.cos(theta1 + theta2) + L3 * np.cos(theta1 + theta2 + theta3)
    partial_y_theta3 = L3 * np.cos(theta1 + theta2 + theta3)

    jacobian = np.array([
        [partial_x_theta1, partial_x_theta2, partial_x_theta3],
        [partial_y_theta1, partial_y_theta2, partial_y_theta3]
    ])
    return jacobian

def evaluate_jacobian_accuracy(model, test_set, num_samples, show_details):
    frobenius_norms = []

    # Convert test_set to numpy for efficient operations
    test_set_array = test_set.to_numpy()

    # Select random samples for comparison
    selected_indices = random.sample(range(len(test_set_array)), num_samples)

    for idx in selected_indices:
        sample = test_set_array[idx]  # Extract a single test sample
        step_size = 0.1

        # Compute the Jacobian using the learned model
        learned_jacobian = compute_jacobian_numerically(model, sample, step_size)
        if show_details:
            print("Computed Jacobian from the model:")
            for row in learned_jacobian:
                print([f"{val:.12f}" for val in row])

        # Compute the Jacobian analytically
        angles = sample[:3]  # Extract joint angles
        exact_jacobian = calc_analytical_jacobian(angles)
        if show_details:
            print("\nAnalytically derived Jacobian:")
            print(exact_jacobian)
            print("\n")

        # Calculate the Frobenius norm between the two matrices
        distance = np.linalg.norm(learned_jacobian - exact_jacobian, ord='fro')
        frobenius_norms.append(distance)

    # Display summary statistics
    print(f"Average Frobenius Norm: {np.mean(frobenius_norms):.6f}")
    print(f"Standard Deviation of Frobenius Norm: {np.std(frobenius_norms):.6f}")

"""###Compare the Learned Jacobian to the Analytical Jacobian

To compare:


Compare element-by-element or using a norm (e.g., Frobenius norm).
"""

evaluate_jacobian_accuracy(model, Xr3_10k_test, 20, False)

"""#5 joints robot (r5)

## Explorative data analisys

###r5 dataset
"""

import pandas as pd

# Load the CSV file with the correct delimiter
file_path = '/content/drive/MyDrive/homework ML/ML/MLHW1_robot_kinematics/logfile_r5.csv'
data_r5 = pd.read_csv(file_path, delimiter=';')

# Separate features and labels
features_r5 = data_r5[['j0', 'j1','j2','j3','j4']]
labels_r5 = data_r5[['ft_x', 'ft_y', 'ft_z', 'ft_qw', 'ft_qx', 'ft_qy', 'ft_qz']]

"""###r5 with 1492 seed dataset"""

import pandas as pd

# Load the CSV file with the correct delimiter
file_path = '/content/drive/MyDrive/homework ML/ML/MLHW1_robot_kinematics/logfile_seed1492_r5.csv'
data_r5_1492 = pd.read_csv(file_path, delimiter=';')

# Separate features and labels
features_r5_1492 = data_r5_1492[['j0', 'j1','j2','j3','j4']]
labels_r5_1492 = data_r5_1492[['ft_x', 'ft_y', 'ft_z', 'ft_qw', 'ft_qx', 'ft_qy', 'ft_qz']]

from tabulate import tabulate
print(tabulate(data_r5.head(20), headers='keys', tablefmt='fancy_grid'))

from tabulate import tabulate
print(tabulate(features_r5.head(20), headers='keys', tablefmt='fancy_grid'))

from tabulate import tabulate
print(tabulate(labels_r5.head(20), headers='keys', tablefmt='fancy_grid'))

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Assuming labels are in a dataframe or similar structure
fingertip_positions = labels_r5[['ft_x', 'ft_y', 'ft_z']]

# Create a 3D scatter plot
fig = plt.figure(figsize=(20, 10))
ax = fig.add_subplot(111, projection='3d')

ax.scatter(fingertip_positions['ft_x'],
           fingertip_positions['ft_y'],
           fingertip_positions['ft_z'],
           c='blue', alpha=0.6, label='Fingertip Position')

ax.set_xlabel('ft_x')
ax.set_ylabel('ft_y')
ax.set_zlabel('ft_z')
ax.set_title('Fingertip Positions in Cartesian Space')
plt.legend()
plt.show()

"""###3D position and orientation"""

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from scipy.spatial.transform import Rotation as R

# Extract position (ft_x, ft_y, ft_z) and quaternion orientation (ft_qw, ft_qx, ft_qy, ft_qz)
ft_x = labels_r5['ft_x']
ft_y = labels_r5['ft_y']
ft_z = labels_r5['ft_z']
ft_qw = labels_r5['ft_qw']
ft_qx = labels_r5['ft_qx']
ft_qy = labels_r5['ft_qy']
ft_qz = labels_r5['ft_qz']
ft_positions = np.array([ft_x, ft_y, ft_z]).T
ft_quaternions = np.array([ft_qw, ft_qx, ft_qy, ft_qz]).T

# Convert quaternions to rotation vectors
rotations = R.from_quat(ft_quaternions)
rotation_vectors = rotations.as_rotvec()  # Shape: (N, 3)

# Normalize rotation vectors for visualization (scaled arrows)
arrow_vectors = rotation_vectors / np.linalg.norm(rotation_vectors, axis=1, keepdims=True)

# Create a 3D scatter plot for positions and overlay orientation vectors
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Plot fingertip positions
ax.scatter(ft_positions[:, 0], ft_positions[:, 1], ft_positions[:, 2], c='blue', label='Positions', s=10)

# Add orientation vectors
for pos, vec in zip(ft_positions, arrow_vectors):
    ax.quiver(pos[0], pos[1], pos[2], vec[0], vec[1], vec[2], color='red', length=0.1, normalize=True)

# Labels and legend
ax.set_xlabel('ft_x')
ax.set_ylabel('ft_y')
ax.set_zlabel('ft_z')
ax.legend()
plt.title('Fingertip Position and Orientation')
plt.show()

"""###data splitting"""

from sklearn.model_selection import train_test_split
#using features with base seed and labels with different seed
Xr5_train, Xr5_test_disposable, Yr5_train, Yr5_test_disposable = train_test_split(features_r5, labels_r5, test_size=0.2, random_state=42)
Xr5_train_disposable, Xr5_test, Yr5_train_disposable, Yr5_test = train_test_split(features_r5_1492, labels_r5_1492, test_size=0.2, random_state=42)

"""##model
R5 is the most complex robot configuration, with 5 degrees of freedom.

For this model I'll try with a deep forward neural network
"""

!pip install scikeras

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import GridSearchCV, KFold
from sklearn.metrics import mean_squared_error
from scikeras.wrappers import KerasRegressor

def create_model(learning_rate=0.001, hidden_layers=[16, 32, 64]):
    model = keras.Sequential()
    model.add(layers.InputLayer(shape=(Xr5_train.shape[1],)))

    # Dynamically add hidden layers
    for neurons in hidden_layers:
        model.add(layers.Dense(neurons, activation='relu'))

    # Output layer
    model.add(layers.Dense(Yr5_train.shape[1], activation='linear'))  # Linear output layer

    # Compile the model
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
                  loss='mean_squared_error')

    return model

# Wrap the model for use in GridSearchCV
def create_model_wrapper(learning_rate=0.001, hidden_layers=[16, 32, 64]):
    return KerasRegressor(model=create_model, learning_rate=learning_rate, hidden_layers=hidden_layers, epochs=10, batch_size=32, verbose=0)


# Hyperparameters for Grid Search
param_grid = {
    'learning_rate': [0.001, 0.01, 0.1],
    'epochs': [20, 30, 50],
    'batch_size': [16, 32],
    'hidden_layers': [
        [16, 32],         # 2 layers
        [16, 32, 64],    # 3 layers
        [16, 32, 64, 126]  # 4 layers
    ]
}


# Cross-validation setup
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Perform grid search
grid_search = GridSearchCV(estimator=create_model_wrapper(), param_grid=param_grid, cv=kf, scoring='neg_mean_squared_error', verbose = 10)

"""###first try"""

# Perform grid search to find the best hyperparameters
grid_search.fit(Xr5_train, Yr5_train)

# Get best parameters and results
best_params = grid_search.best_params_
print("Best Parameters from Grid Search:", best_params)

best_score = grid_search.best_score_
print("Best MSE Score from Grid Search:", -best_score)

"""####evalutation and metrics"""

# Create the best model with the selected hyperparameters
best_model = create_model(learning_rate=best_params['learning_rate'])

# Train the model on the entire training data with the best epochs
history = best_model.fit(Xr5_train, Yr5_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1, validation_split=0.2)

# Predict the position and orientation
predictions = best_model.predict(Xr5_test)

# Calculate Mean Squared Error (MSE) on predictions
mse = mean_squared_error(Yr5_test, predictions)
print(f"Test MSE: {mse}")
print(f"Train MSE: {-grid_search.best_score_}")

import matplotlib.pyplot as plt

# Plot training and validation loss
def plot_loss_curves(history):
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss (MSE)')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid()
    plt.show()

# Assuming you stored the training history from `fit`
plot_loss_curves(history)

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D  # Import 3D plotting toolkit

# Convert to NumPy arrays
Y_true = Yr5_test.to_numpy() if not isinstance(Yr5_test, np.ndarray) else Yr5_test
Y_pred = predictions if isinstance(predictions, np.ndarray) else np.array(predictions)

# Create the figure and subplots
fig = plt.figure(figsize=(20, 10))

# Plot Ground Truth
ax1 = fig.add_subplot(121, projection='3d')  # 1 row, 2 columns, 1st subplot
ax1.scatter(Y_true[:, 0], Y_true[:, 1], Y_true[:, 2], c='blue', alpha=0.6, label='Ground Truth', s=30)
ax1.set_xlabel('ft_x')
ax1.set_ylabel('ft_y')
ax1.set_zlabel('ft_z')
ax1.set_title('Ground Truth Positions')
ax1.legend()

# Plot Predictions
ax2 = fig.add_subplot(122, projection='3d')  # 1 row, 2 columns, 2nd subplot
ax2.scatter(Y_pred[:, 0], Y_pred[:, 1], Y_pred[:, 2], c='orange', alpha=0.7, label='Predictions', s=30)
ax2.set_xlabel('ft_x')
ax2.set_ylabel('ft_y')
ax2.set_zlabel('ft_z')
ax2.set_title('Predicted Positions')
ax2.legend()

# Show the plots
plt.tight_layout()
plt.show()

"""###second try- enhancing performances

####10k samples dataset
"""

import pandas as pd

# Load the CSV file with the correct delimiter
file_path = '/content/drive/MyDrive/homework ML/ML/MLHW1_robot_kinematics/dataset_r5_10ksamples_seed1000.csv'
data_r5 = pd.read_csv(file_path, delimiter=';')

# Separate features and labels
features_r5 = data_r5[['j0', 'j1','j2','j3','j4']]
labels_r5 = data_r5[['ft_x', 'ft_y', 'ft_z', 'ft_qw', 'ft_qx', 'ft_qy', 'ft_qz']]

import pandas as pd

# Load the CSV file with the correct delimiter
file_path = '/content/drive/MyDrive/homework ML/ML/MLHW1_robot_kinematics/dataset_r5_10ksamples_seed1492.csv'
data_r5_1492 = pd.read_csv(file_path, delimiter=';')

# Separate features and labels
features_r5_1492 = data_r5_1492[['j0', 'j1','j2','j3','j4']]
labels_r5_1492 = data_r5_1492[['ft_x', 'ft_y', 'ft_z', 'ft_qw', 'ft_qx', 'ft_qy', 'ft_qz']]

from tabulate import tabulate
print(tabulate(data_r5.head(20), headers='keys', tablefmt='fancy_grid'))

from tabulate import tabulate
print(tabulate(features_r5.head(20), headers='keys', tablefmt='fancy_grid'))

from tabulate import tabulate
print(tabulate(labels_r5.head(20), headers='keys', tablefmt='fancy_grid'))

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Assuming labels are in a dataframe or similar structure
fingertip_positions = labels_r5[['ft_x', 'ft_y', 'ft_z']]

# Create a 3D scatter plot
fig = plt.figure(figsize=(20, 10))
ax = fig.add_subplot(111, projection='3d')

ax.scatter(fingertip_positions['ft_x'],
           fingertip_positions['ft_y'],
           fingertip_positions['ft_z'],
           c='blue', alpha=0.6, label='Fingertip Position', s=10)

ax.set_xlabel('ft_x')
ax.set_ylabel('ft_y')
ax.set_zlabel('ft_z')
ax.set_title('Fingertip Positions in Cartesian Space')
plt.legend()
plt.show()

"""####3D position and orientation"""

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from scipy.spatial.transform import Rotation as R

# Extract position (ft_x, ft_y, ft_z) and quaternion orientation (ft_qw, ft_qx, ft_qy, ft_qz)
ft_x = labels_r5['ft_x']
ft_y = labels_r5['ft_y']
ft_z = labels_r5['ft_z']
ft_qw = labels_r5['ft_qw']
ft_qx = labels_r5['ft_qx']
ft_qy = labels_r5['ft_qy']
ft_qz = labels_r5['ft_qz']
ft_positions = np.array([ft_x, ft_y, ft_z]).T
ft_quaternions = np.array([ft_qw, ft_qx, ft_qy, ft_qz]).T

# Convert quaternions to rotation vectors
rotations = R.from_quat(ft_quaternions)
rotation_vectors = rotations.as_rotvec()  # Shape: (N, 3)

# Normalize rotation vectors for visualization (scaled arrows)
arrow_vectors = rotation_vectors / np.linalg.norm(rotation_vectors, axis=1, keepdims=True)

# Create a 3D scatter plot for positions and overlay orientation vectors
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Plot fingertip positions
ax.scatter(ft_positions[:, 0], ft_positions[:, 1], ft_positions[:, 2], c='blue', label='Positions', s=10)

# Add orientation vectors
for pos, vec in zip(ft_positions, arrow_vectors):
    ax.quiver(pos[0], pos[1], pos[2], vec[0], vec[1], vec[2], color='red', length=0.1, normalize=True)

# Labels and legend
ax.set_xlabel('ft_x')
ax.set_ylabel('ft_y')
ax.set_zlabel('ft_z')
ax.legend()
plt.title('Fingertip Position and Orientation')
plt.show()

"""####data splitting"""

from sklearn.model_selection import train_test_split
#using features with base seed and labels with different seed
Xr5_train, Xr5_test_disposable, Yr5_train, Yr5_test_disposable = train_test_split(features_r5, labels_r5, test_size=0.2, random_state=42)
Xr5_train_disposable, Xr5_test, Yr5_train_disposable, Yr5_test = train_test_split(features_r5_1492, labels_r5_1492, test_size=0.2, random_state=42)

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import GridSearchCV, KFold
from sklearn.metrics import mean_squared_error
from scikeras.wrappers import KerasRegressor

def create_model(learning_rate=0.001, hidden_layers=[16, 32, 64]):
    model = keras.Sequential()
    model.add(layers.InputLayer(shape=(Xr5_train.shape[1],)))

    # Dynamically add hidden layers
    for neurons in hidden_layers:
        model.add(layers.Dense(neurons, activation='relu'))

    # Output layer
    model.add(layers.Dense(Yr5_train.shape[1], activation='linear'))  # Linear output layer

    # Compile the model
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
                  loss='mean_squared_error')

    return model

# Wrap the model for use in GridSearchCV
def create_model_wrapper(learning_rate=0.001, hidden_layers=[16, 32, 64]):
    return KerasRegressor(model=create_model, learning_rate=learning_rate, hidden_layers=hidden_layers, epochs=10, batch_size=32, verbose=0)


# Hyperparameters for Grid Search
param_grid = {
    'learning_rate': [0.001, 0.01, 0.1],
    'epochs': [20, 30, 50],
    'batch_size': [16, 32],
    'hidden_layers': [
        [16, 32],         # 2 layers
        [16, 32, 64],    # 3 layers
        [16, 32, 64, 126]  # 4 layers
    ]
}


# Cross-validation setup
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Perform grid search
grid_search = GridSearchCV(estimator=create_model_wrapper(), param_grid=param_grid, cv=kf, scoring='neg_mean_squared_error', verbose = 10)

# Perform grid search to find the best hyperparameters
grid_search.fit(Xr5_train, Yr5_train)

# Get best parameters and results
best_params = grid_search.best_params_
print("Best Parameters from Grid Search:", best_params)

best_score = grid_search.best_score_
print("Best MSE Score from Grid Search:", -best_score)

"""####evalutation and metrics"""

# Create the best model with the selected hyperparameters
best_model = create_model(learning_rate=best_params['learning_rate'], hidden_layers = best_params['hidden_layers'])

# Train the model on the entire training data with the best epochs
history = best_model.fit(Xr5_train, Yr5_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1, validation_split=0.2)

# Predict the position and orientation
predictions = best_model.predict(Xr5_test)

# Calculate Mean Squared Error (MSE) on predictions
mse = mean_squared_error(Yr5_test, predictions)
print(f"Test MSE: {mse}")

print(f"Train MSE: {-grid_search.best_score_}")

import matplotlib.pyplot as plt

# Plot training and validation loss
def plot_loss_curves(history):
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss (MSE)')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid()
    plt.show()

# Assuming you stored the training history from `fit`
plot_loss_curves(history)

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D  # Import 3D plotting toolkit

# Convert to NumPy arrays
Y_true = Yr5_test.to_numpy() if not isinstance(Yr5_test, np.ndarray) else Yr5_test
Y_pred = predictions if isinstance(predictions, np.ndarray) else np.array(predictions)

# Create the figure and subplots
fig = plt.figure(figsize=(20, 10))

# Plot Ground Truth
ax1 = fig.add_subplot(121, projection='3d')  # 1 row, 2 columns, 1st subplot
ax1.scatter(Y_true[:, 0], Y_true[:, 1], Y_true[:, 2], c='blue', alpha=0.6, label='Ground Truth')
ax1.set_xlabel('ft_x')
ax1.set_ylabel('ft_y')
ax1.set_zlabel('ft_z')
ax1.set_title('Ground Truth Positions')
ax1.legend()

# Plot Predictions
ax2 = fig.add_subplot(122, projection='3d')  # 1 row, 2 columns, 2nd subplot
ax2.scatter(Y_pred[:, 0], Y_pred[:, 1], Y_pred[:, 2], c='orange', alpha=0.7, label='Predictions')
ax2.set_xlabel('ft_x')
ax2.set_ylabel('ft_y')
ax2.set_zlabel('ft_z')
ax2.set_title('Predicted Positions')
ax2.legend()

# Show the plots
plt.tight_layout()
plt.show()

"""##Compute the Jacobian Matrix 𝐽"""

import tensorflow as tf

def FK(model,theta):
    # reshape to batch size 1
    t = tf.reshape(theta, shape=(1,5))
    out = model(t)
    # reshape to 1d vector
    out = tf.reshape(out, shape=(7,))
    return out

@tf.function
def FK_Jacobian(model,x):
  with tf.GradientTape(persistent=True) as tape:
    tape.watch(x)
    y = FK(model,x)
  return tape.jacobian(y, x)

"""###Analytical Jacobian
Calculate the analytical Jacobian using the following known FK equations:






"""

import numpy as np
import math
# Example:
q1 = Xr5_train['j0'][1]
q2 = Xr5_train['j1'][1]
q3 = Xr5_train['j2'][1]
q4 = Xr5_train['j3'][1]
q5 = Xr5_train['j4'][1]
L1, L2, L3, L4, L5 = 0.1, 0.1, 0.1, 0.1, 0.1
analytical_jacobian = np.array([[-math.sin(q1)*(L5*math.cos(q2 + q3 + q4 + q5) + L3*math.cos(q2 + q3) + L2*math.cos(q2) + L4*math.cos(q2 + q3 + q4)), -math.cos(q1)*(L5*math.sin(q2 + q3 + q4 + q5) + L3*math.sin(q2 + q3) + L2*math.sin(q2) + L4*math.sin(q2 + q3 + q4)), -math.cos(q1)*(L5*math.sin(q2 + q3 + q4 + q5) + L3*math.sin(q2 + q3) + L4*math.sin(q2 + q3 + q4)), -math.cos(q1)*(L5*math.sin(q2 + q3 + q4 + q5) + L4*math.sin(q2 + q3 + q4)), -L5*math.sin(q2 + q3 + q4 + q5)*math.cos(q1)],
              [math.cos(q1)*(L5*math.cos(q2 + q3 + q4 + q5) + L3*math.cos(q2 + q3) + L2*math.cos(q2) + L4*math.cos(q2 + q3 + q4)), -math.sin(q1)*(L5*math.sin(q2 + q3 + q4 + q5) + L3*math.sin(q2 + q3) + L2*math.sin(q2) + L4*math.sin(q2 + q3 + q4)), -math.sin(q1)*(L5*math.sin(q2 + q3 + q4 + q5) + L3*math.sin(q2 + q3) + L4*math.sin(q2 + q3 + q4)), -math.sin(q1)*(L5*math.sin(q2 + q3 + q4 + q5) + L4*math.sin(q2 + q3 + q4)), -L5*math.sin(q2 + q3 + q4 + q5)*math.sin(q1)],
              [                                                                                         0,                                                                                        0,                                                                                        0,                                                                                        0,                                                                                        0]]
                               )
print(analytical_jacobian)

"""###Compute distances and compare the Learned Jacobians to the Analytical Jacobian

To compare:


Compare element-by-element or using a norm (e.g., Frobenius norm).
"""

differences = []
for i in Xr5_test.index:
  q1 = Xr5_test['j0'][i]
  q2 = Xr5_test['j1'][i]
  q3 = Xr5_test['j2'][i]
  q4 = Xr5_test['j3'][i]
  q5 = Xr5_test['j4'][i]
  L1, L2, L3, L4, L5 = 0.1, 0.1, 0.1, 0.1, 0.1
  analytical_jacobian = np.array([ [-sin(q1)*(L5*cos(q2 + q3 + q4 + q5) + L3*cos(q2 + q3) + L2*cos(q2) + L4*cos(q2 + q3 + q4)), -cos(q1)*(L5*sin(q2 + q3 + q4 + q5) + L3*sin(q2 + q3) + L2*sin(q2) + L4*sin(q2 + q3 + q4)), -cos(q1)*(L5*sin(q2 + q3 + q4 + q5) + L3*sin(q2 + q3) + L4*sin(q2 + q3 + q4)), -cos(q1)*(L5*sin(q2 + q3 + q4 + q5) + L4*sin(q2 + q3 + q4)), -L5*sin(q2 + q3 + q4 + q5)*cos(q1)]
                                  [ cos(q1)*(L5*cos(q2 + q3 + q4 + q5) + L3*cos(q2 + q3) + L2*cos(q2) + L4*cos(q2 + q3 + q4)), -sin(q1)*(L5*sin(q2 + q3 + q4 + q5) + L3*sin(q2 + q3) + L2*sin(q2) + L4*sin(q2 + q3 + q4)), -sin(q1)*(L5*sin(q2 + q3 + q4 + q5) + L3*sin(q2 + q3) + L4*sin(q2 + q3 + q4)), -sin(q1)*(L5*sin(q2 + q3 + q4 + q5) + L4*sin(q2 + q3 + q4)), -L5*sin(q2 + q3 + q4 + q5)*sin(q1)]
                                  [                                                                                         0,            L5*cos(q2 + q3 + q4 + q5) + L3*cos(q2 + q3) + L2*cos(q2) + L4*cos(q2 + q3 + q4),            L5*cos(q2 + q3 + q4 + q5) + L3*cos(q2 + q3) + L4*cos(q2 + q3 + q4),            L5*cos(q2 + q3 + q4 + q5) + L4*cos(q2 + q3 + q4),          L5*cos(q2 + q3 + q4 + q5)]]
                                   )



  x = [q1,q2,q3,q4,q5]
  t = tf.constant(x, dtype=tf.float32)
  jacobian = FK_Jacobian(best_model, t)

  # Print the Jacobian matrix
  jacobian.numpy()  # Convert TensorFlow tensor to NumPy array for readability
  jacobian = np.delete(jacobian, [3,4,5,6], axis=0)    #I'm gonna remove the part of the jacobian that refers to quaternions as I want just positions
  # Assuming analytical_J and learned_J are the Jacobian matrices
  diff = np.linalg.norm(analytical_jacobian - jacobian, ord='fro')
  differences.append(diff)

print(f"the difference of jacobians has been computed on {len(differences)} samples")  #number of differences calculated
mean = np.mean(differences)
print(f"The mean of all the differences is: {mean}")